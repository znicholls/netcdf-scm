Start: 2019-07-18 13:49:39.213926
End: 2019-07-18 13:49:42.048095
Diff: 2.834169
Wrote profile results to scratch.py.lprof
Timer unit: 1e-06 s

Total time: 2.82688 s
File: /home/UNIMELB/znicholls/Documents/AGCEC/Misc/netcdf-scm/src/netcdf_scm/cli.py
Function: crunch_data at line 87

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    87                                           @click.command(context_settings={"help_option_names": ["-h", "--help"]})
    88                                           @click.argument("src", type=click.Path(exists=True, readable=True, resolve_path=True))
    89                                           @click.argument(
    90                                               "dst", type=click.Path(file_okay=False, writable=True, resolve_path=True)
    91                                           )
    92                                           @click.argument("crunch_contact")
    93                                           @click.option(
    94                                               "--drs",
    95                                               default="Scm",
    96                                               type=click.Choice(["Scm", "MarbleCMIP5", "CMIP6Input4MIPs", "CMIP6Output"]),
    97                                               show_default=True,
    98                                               help="Data reference syntax to use for crunching.",
    99                                           )
   100                                           @click.option(
   101                                               "--regexp",
   102                                               default="^((?!fx).)*$",
   103                                               show_default=True,
   104                                               help="Regular expression to apply to file directory (only crunches matches).",
   105                                           )
   106                                           @click.option(
   107                                               "--land-mask-threshold",
   108                                               default=50.0,
   109                                               show_default=True,
   110                                               help="Minimum land fraction for a box to be considered land.",
   111                                           )
   112                                           @click.option(
   113                                               "--data-sub-dir",
   114                                               default="netcdf-scm-crunched",
   115                                               show_default=True,
   116                                               help="Sub-directory of ``dst`` to save data in.",
   117                                           )
   118                                           @click.option(
   119                                               "--force/--do-not-force",  # pylint:disable=too-many-arguments
   120                                               "-f",
   121                                               help="Overwrite any existing files.",
   122                                               default=False,
   123                                               show_default=True,
   124                                           )
   125                                           @click.option(
   126                                               "--small-number-workers",  # pylint:disable=too-many-arguments
   127                                               default=10,
   128                                               show_default=True,
   129                                               help="Maximum number of workers to use when crunching files.",
   130                                           )
   131                                           @click.option(
   132                                               "--small-threshold",  # pylint:disable=too-many-arguments
   133                                               default=300,
   134                                               show_default=True,
   135                                               help="Maximum number of years in a file for it to be processed in parallel with ``small-number-workers``",
   136                                           )
   137                                           @click.option(
   138                                               "--medium-number-workers",
   139                                               default=3,  # pylint:disable=too-many-arguments,too-many-locals,too-many-statements
   140                                               show_default=True,
   141                                               help="Maximum number of workers to use when crunching files.",
   142                                           )
   143                                           @click.option(
   144                                               "--medium-threshold",  # pylint:disable=too-many-arguments
   145                                               default=900,
   146                                               show_default=True,
   147                                               help="Maximum number of years in a file for it to be processed in parallel with ``medium-number-workers``",
   148                                           )
   149                                           @profile
   150                                           def crunch_data(
   151                                               src,
   152                                               dst,
   153                                               crunch_contact,
   154                                               drs,
   155                                               regexp,
   156                                               land_mask_threshold,
   157                                               data_sub_dir,
   158                                               force,
   159                                               small_number_workers,
   160                                               small_threshold,
   161                                               medium_number_workers,
   162                                               medium_threshold,
   163                                           ):
   164                                               r"""
   165                                               Crunch data in ``src`` to NetCDF-SCM ``.nc`` files in ``dst``.
   166                                           
   167                                               ``src`` is searched recursively and netcdf-scm will attempt to crunch all the files
   168                                               found. The directory structure in ``src`` will be mirrored in ``dst``.
   169                                           
   170                                               Failures and warnings are recorded and written into a text file in ``dst``. We
   171                                               recommend examining this file using a file analysis tool such as ``grep``. We
   172                                               often use the command ``grep "\|WARNING\|INFO\|ERROR <log-file>``.
   173                                           
   174                                               ``crunch_contact`` is written into the output ``.nc`` files' ``crunch_contact``
   175                                               attribute.
   176                                               """
   177         5         26.0      5.2      0.0      output_prefix = "netcdf-scm"
   178         5         19.0      3.8      0.0      separator = "_"
   179         5         73.0     14.6      0.0      out_dir = os.path.join(dst, data_sub_dir)
   180                                           
   181         5         19.0      3.8      0.0      log_file = os.path.join(
   182         5         17.0      3.4      0.0          out_dir,
   183         5        111.0     22.2      0.0          "{}-crunch.log".format(_get_timestamp().replace(" ", "_").replace(":", "")),
   184                                               )
   185         5         85.0     17.0      0.0      _make_path_if_not_exists(out_dir)
   186         5         20.0      4.0      0.0      init_logging(
   187                                                   [
   188         5         18.0      3.6      0.0              ("crunch-contact", crunch_contact),
   189         5         18.0      3.6      0.0              ("source", src),
   190         5         17.0      3.4      0.0              ("destination", out_dir),
   191         5         18.0      3.6      0.0              ("drs", drs),
   192         5         32.0      6.4      0.0              ("regexp", regexp),
   193         5         17.0      3.4      0.0              ("land_mask_threshold", land_mask_threshold),
   194         5         22.0      4.4      0.0              ("force", force),
   195         5         18.0      3.6      0.0              ("small_number_workers", small_number_workers),
   196         5         32.0      6.4      0.0              ("small_threshold", small_threshold),
   197         5         17.0      3.4      0.0              ("medium_number_workers", medium_number_workers),
   198         5         19.0      3.8      0.0              ("medium_threshold", medium_threshold),
   199                                                   ],
   200         5      18382.0   3676.4      0.7          out_filename=log_file,
   201                                               )
   202                                           
   203         5       2802.0    560.4      0.1      tracker = OutputFileDatabase(out_dir)
   204         5        664.0    132.8      0.0      regexp_to_match = re.compile(regexp)
   205         5         62.0     12.4      0.0      helper = _get_scmcube_helper(drs)
   206                                           
   207         5         18.0      3.6      0.0      dirs_to_crunch = []
   208         5       1449.0    289.8      0.1      logger.info("Finding directories with files")
   209        10        356.0     35.6      0.0      for dirpath, _, filenames in walk(src):
   210         5       1085.0    217.0      0.0          logger.debug("Entering %s", dirpath)
   211         5         23.0      4.6      0.0          if filenames:
   212         5         68.0     13.6      0.0              if not regexp_to_match.match(dirpath):
   213                                                           logger.debug("Skipping (did not match regexp) %s", dirpath)
   214                                                           continue
   215         5       1410.0    282.0      0.0              logger.info("Adding directory to queue %s", dirpath)
   216         5         38.0      7.6      0.0              helper = _get_scmcube_helper(drs)
   217         5         17.0      3.4      0.0              try:
   218         5         24.0      4.8      0.0                  helper._add_time_period_from_files_in_directory(  # pylint:disable=protected-access
   219         5      13984.0   2796.8      0.5                      dirpath
   220                                                           )
   221                                                       except Exception as e:  # pylint:disable=broad-except
   222                                                           logger.debug("Ignoring broken directory %s with error %s", dirpath, e)
   223                                                           continue
   224         5         28.0      5.6      0.0              time_ids = helper._time_id.split(  # pylint:disable=protected-access
   225         5         21.0      4.2      0.0                  helper.time_period_separator
   226                                                       )
   227         5         27.0      5.4      0.0              start_year = int(time_ids[0][:4].lstrip("0"))
   228         5         24.0      4.8      0.0              end_year = int(time_ids[1][:4].lstrip("0"))
   229         5         18.0      3.6      0.0              num_years = end_year - start_year
   230         5         21.0      4.2      0.0              dirs_to_crunch.append((dirpath, filenames, num_years))
   231                                           
   232         5         22.0      4.4      0.0      def keep_dir(dpath):
   233                                                   if not regexp_to_match.match(dpath):
   234                                                       logger.debug("Skipping (did not match regexp) %s", dpath)
   235                                                       return False
   236                                                   logger.info("Adding directory to queue %s", dpath)
   237                                                   try:
   238                                                       helper._add_time_period_from_files_in_directory(  # pylint:disable=protected-access
   239                                                           dpath
   240                                                       )
   241                                                   except Exception as e:  # pylint:disable=broad-except
   242                                                       logger.debug("Ignoring broken directory %s with error %s", dpath, e)
   243                                                       return False
   244                                                   return True
   245                                           
   246         5      15188.0   3037.6      0.5      dirs_to_crunch = _find_dirs_meeting_func(src, keep_dir)
   247                                           
   248         5         24.0      4.8      0.0      def get_nyears(dpath_h):
   249                                                   helper._add_time_period_from_files_in_directory(  # pylint:disable=protected-access
   250                                                       dpath_h
   251                                                   )
   252                                                   time_ids = helper._time_id.split(  # pylint:disable=protected-access
   253                                                       helper.time_period_separator
   254                                                   )
   255                                                   start_year = int(time_ids[0][:4].lstrip("0"))
   256                                                   end_year = int(time_ids[1][:4].lstrip("0"))
   257                                                   num_years = end_year - start_year
   258                                           
   259                                                   return num_years
   260                                           
   261         5       9374.0   1874.8      0.3      dirs_to_crunch = [(d, f, get_nyears(d)) for d, f in dirs_to_crunch]
   262                                           
   263                                               crunch_kwargs = {
   264         5         21.0      4.2      0.0          "drs": drs,
   265         5         18.0      3.6      0.0          "separator": separator,
   266         5         17.0      3.4      0.0          "output_prefix": output_prefix,
   267         5         19.0      3.8      0.0          "out_dir": out_dir,
   268         5         18.0      3.6      0.0          "force": force,
   269         5         19.0      3.8      0.0          "existing_files": tracker._data,  # pylint:disable=protected-access
   270         5         18.0      3.6      0.0          "land_mask_threshold": land_mask_threshold,
   271         5         22.0      4.4      0.0          "crunch_contact": crunch_contact,
   272                                               }
   273                                           
   274         5         20.0      4.0      0.0      def process_results(res):
   275                                                   if res is None:
   276                                                       return  # skipped crunching
   277                                                   scm_timeseries_cubes, out_filepath, info = res
   278                                                   logger.info("Registering %s", out_filepath)
   279                                                   tracker.register(out_filepath, info)
   280                                                   logger.info("Writing file to %s", out_filepath)
   281                                                   save_netcdf_scm_nc(scm_timeseries_cubes, out_filepath)
   282                                           
   283         5         19.0      3.8      0.0      def crunch_from_list(crunch_list, n_workers=1):
   284                                                   return _apply_func(
   285                                                       _crunch_files,
   286                                                       crunch_list,
   287                                                       common_kwarglist=crunch_kwargs,
   288                                                       postprocess_func=process_results,
   289                                                       n_workers=n_workers,
   290                                                       style="processes",
   291                                                   )
   292                                           
   293         5         17.0      3.4      0.0      failures_small = False
   294                                               dirs_to_crunch_small = [
   295         5         30.0      6.0      0.0          {"fnames": f, "dpath": d} for d, f, n in dirs_to_crunch if n < small_threshold
   296                                               ]
   297         5         20.0      4.0      0.0      logger.info(
   298         5         17.0      3.4      0.0          "Crunching %s directories with less than %s years of data",
   299         5         19.0      3.8      0.0          len(dirs_to_crunch_small),
   300         5       1493.0    298.6      0.1          small_threshold,
   301                                               )
   302         5         21.0      4.2      0.0      if dirs_to_crunch_small:
   303         5         17.0      3.4      0.0          failures_small = crunch_from_list(
   304         5    2755859.0 551171.8     97.5              dirs_to_crunch_small, n_workers=small_number_workers
   305                                                   )
   306                                           
   307         5         24.0      4.8      0.0      failures_medium = False
   308                                               dirs_to_crunch_medium = [
   309         5         23.0      4.6      0.0          {"fnames": f, "dpath": d}
   310         5         32.0      6.4      0.0          for d, f, n in dirs_to_crunch
   311                                                   if small_threshold <= n < medium_threshold
   312                                               ]
   313         5         20.0      4.0      0.0      logger.info(
   314         5         17.0      3.4      0.0          "Crunching %s directories with greater than or equal to %s and less than %s years of data",
   315         5         20.0      4.0      0.0          len(dirs_to_crunch_medium),
   316         5         18.0      3.6      0.0          small_threshold,
   317         5       1698.0    339.6      0.1          medium_threshold,
   318                                               )
   319         5         22.0      4.4      0.0      if dirs_to_crunch_medium:
   320                                                   failures_medium = crunch_from_list(
   321                                                       dirs_to_crunch_medium, n_workers=medium_number_workers
   322                                                   )
   323                                           
   324         5         19.0      3.8      0.0      failures_large = False
   325                                               dirs_to_crunch_large = [
   326         5         30.0      6.0      0.0          {"fnames": f, "dpath": d} for d, f, n in dirs_to_crunch if n > medium_threshold
   327                                               ]
   328         5         20.0      4.0      0.0      logger.info(
   329         5         17.0      3.4      0.0          "Crunching %s directories with greater than or equal to %s years of data",
   330         5         32.0      6.4      0.0          len(dirs_to_crunch_large),
   331         5       1426.0    285.2      0.1          medium_threshold,
   332                                               )
   333         5         33.0      6.6      0.0      if dirs_to_crunch_large:
   334                                                   failures_large = crunch_from_list(dirs_to_crunch_large, n_workers=1)
   335                                           
   336         5         20.0      4.0      0.0      if failures_small or failures_medium or failures_large:
   337                                                   raise click.ClickException(
   338                                                       "Some files failed to process. See {} for more details".format(log_file)
   339                                                   )

Total time: 1.94426 s
File: /home/UNIMELB/znicholls/Documents/AGCEC/Misc/netcdf-scm/src/netcdf_scm/iris_cube_wrappers.py
Function: get_scm_timeseries_cubes at line 619

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   619                                               @profile
   620                                               def get_scm_timeseries_cubes(
   621                                                   self,
   622                                                   sftlf_cube=None,
   623                                                   land_mask_threshold=50,
   624                                                   areacella_scmcube=None,
   625                                                   masks=None,
   626                                               ):
   627                                                   """
   628                                                   Get SCM relevant cubes
   629                                           
   630                                                   If global, Northern Hemisphere and Southern Hemisphere land cubes are
   631                                                   calculated, then three auxillary co-ordinates are also added to each cube:
   632                                                   ``land_fraction``, ``land_fraction_northern_hemisphere`` and
   633                                                   ``land_fraction_southern_hemisphere``. These co-ordinates document the area
   634                                                   fraction that was considered to be land when the cubes were crunched i.e.
   635                                                   ``land_fraction`` is the fraction of the entire globe which was considered to
   636                                                   be land, ``land_fraction_northern_hemisphere`` is the fraction of the Northern
   637                                                   Hemisphere which was considered to be land and
   638                                                   ``land_fraction_southern_hemisphere`` is the fraction of the Southern
   639                                                   Hemisphere which was considered to be land.
   640                                           
   641                                                   Parameters
   642                                                   ----------
   643                                                   sftlf_cube : :obj:`SCMCube`, optional
   644                                                       land surface fraction data which is used to determine whether a given
   645                                                       gridbox is land or ocean. If ``None``, we try to load the land surface
   646                                                       fraction automatically.
   647                                           
   648                                                   land_mask_threshold : float, optional
   649                                                       if the surface land fraction in a grid box is greater than
   650                                                       ``land_mask_threshold``, it is considered to be a land grid box.
   651                                           
   652                                                   areacella_scmcube : :obj:`SCMCube`, optional
   653                                                       cell area data which is used to take the latitude-longitude mean of the
   654                                                       cube's data. If ``None``, we try to load this data automatically and if
   655                                                       that fails we fall back onto ``iris.analysis.cartography.area_weights``.
   656                                           
   657                                                   masks : list[str]
   658                                                       List of masks to use. If ``None`` then
   659                                                       ``netcdf_scm.masks.DEFAULT_REGIONS`` is used.
   660                                           
   661                                                   Returns
   662                                                   -------
   663                                                   dict
   664                                                       Cubes, with latitude-longitude mean data as appropriate for each of the
   665                                                       SCM relevant regions.
   666                                                   """
   667         5         12.0      2.4      0.0          masks = masks if masks is not None else DEFAULT_REGIONS
   668         5         10.0      2.0      0.0          scm_masks = self._get_scm_masks(
   669         5     198990.0  39798.0     10.2              sftlf_cube=sftlf_cube, land_mask_threshold=land_mask_threshold, masks=masks
   670                                                   )
   671         5      41524.0   8304.8      2.1          area_weights = self._get_area_weights(areacella_scmcube=areacella_scmcube)
   672         5        233.0     46.6      0.0          @profile
   673                                                   def crunch_timeseries(region, numpy_mask):
   674                                                       scm_cube = self._get_masked_cube_with_metdata(
   675                                                           region, numpy_mask, land_mask_threshold
   676                                                       )
   677                                           
   678                                                       if region in _LAND_FRACTION_REGIONS:
   679                                                           area = self._get_area(scm_cube, area_weights)
   680                                                       else:
   681                                                           area = None
   682                                                       return region, take_lat_lon_mean(scm_cube, area_weights), area
   683                                           
   684         5          9.0      1.8      0.0          try:
   685         5    1677461.0 335492.2     86.3              crunch_list = self._crunch_in_memory(crunch_timeseries, scm_masks)
   686                                                   except MemoryError:
   687                                                       logger.warning(
   688                                                           "Data won't fit in memory, will process lazily (hence slowly)"
   689                                                       )
   690                                                       data_dir = dirname(self.info["files"][0])
   691                                                       self.__init__()
   692                                                       self.load_data_in_directory(data_dir)
   693                                                       crunch_list = self._crunch_serial(crunch_timeseries, scm_masks)
   694                                           
   695         5         48.0      9.6      0.0          timeseries_cubes = {mask: ts_cube for mask, ts_cube, _ in crunch_list}
   696         5         28.0      5.6      0.0          areas = {mask: area for mask, _, area in crunch_list if area is not None}
   697         5      25937.0   5187.4      1.3          timeseries_cubes = self._add_land_fraction(timeseries_cubes, areas)
   698         5         10.0      2.0      0.0          return timeseries_cubes

Total time: 1.33875 s
File: /home/UNIMELB/znicholls/Documents/AGCEC/Misc/netcdf-scm/src/netcdf_scm/iris_cube_wrappers.py
Function: crunch_timeseries at line 672

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   672                                                   @profile
   673                                                   def crunch_timeseries(region, numpy_mask):
   674        45        167.0      3.7      0.0              scm_cube = self._get_masked_cube_with_metdata(
   675        45     104280.0   2317.3      7.8                  region, numpy_mask, land_mask_threshold
   676                                                       )
   677                                           
   678        45         96.0      2.1      0.0              if region in _LAND_FRACTION_REGIONS:
   679        30      16963.0    565.4      1.3                  area = self._get_area(scm_cube, area_weights)
   680                                                       else:
   681        15         10.0      0.7      0.0                  area = None
   682        45    1217230.0  27049.6     90.9              return region, take_lat_lon_mean(scm_cube, area_weights), area

Total time: 1.67737 s
File: /home/UNIMELB/znicholls/Documents/AGCEC/Misc/netcdf-scm/src/netcdf_scm/iris_cube_wrappers.py
Function: _crunch_in_memory at line 699

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   699                                               @profile
   700                                               def _crunch_in_memory(self, crunch_timeseries, scm_masks):
   701                                                   # crunching in parallel could go here
   702         5     335144.0  67028.8     20.0          self._ensure_data_realised()
   703         5       1838.0    367.6      0.1          logger.debug("Crunching SCM timeseries in memory")
   704         5    1340393.0 268078.6     79.9          return self._crunch_serial(crunch_timeseries, scm_masks)

