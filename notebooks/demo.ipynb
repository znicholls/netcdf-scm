{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling netCDF files for simple climate models\n",
    "\n",
    "In this notebook we give a brief introduction to iris, the library we use for our analysis, before giving a demonstration of some of the key functionality of `netcdf_scm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) { return false; }"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "import os\n",
    "from os.path import join\n",
    "import datetime\n",
    "import warnings\n",
    "from dateutil import parser\n",
    "    \n",
    "import numpy as np\n",
    "import iris\n",
    "import iris.coord_categorisation\n",
    "import iris.plot as iplt\n",
    "import iris.quickplot as qplt\n",
    "import iris.analysis.cartography\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as mpl_cm\n",
    "import cftime\n",
    "\n",
    "from netcdf_scm.iris_cube_wrappers import SCMCube, MarbleCMIP5Cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('bmh') \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH_TEST = join(\"..\", \"tests\", \"test-data\")\n",
    "DATA_PATH_TEST_MARBLE_CMIP5_ROOT = join(DATA_PATH_TEST, \"marble-cmip5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a cube\n",
    "\n",
    "### Loading with iris\n",
    "\n",
    "Here we show how to load a cube directly using iris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_file = join(\n",
    "    DATA_PATH_TEST_MARBLE_CMIP5_ROOT,\n",
    "    \"cmip5\",\n",
    "    \"1pctCO2\",\n",
    "    \"Amon\",\n",
    "    \"tas\",\n",
    "    \"CanESM2\",\n",
    "    \"r1i1p1\",\n",
    "    \"tas_Amon_CanESM2_1pctCO2_r1i1p1_185001-198912.nc\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "# Ignore output as the warnings are likely to change with\n",
    "# new iris versions\n",
    "tas_iris_load = SCMCube()\n",
    "# you need this in case your cube has multiple variables\n",
    "variable_constraint = iris.Constraint(\n",
    "    cube_func=(lambda c: c.var_name == np.str(\"tas\"))\n",
    ")\n",
    "\n",
    "tas_iris_load.cube = iris.load_cube(tas_file, variable_constraint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The warning tells us that we need to add the areacella as a measure variable to our cube. Doing this manually everytime involves finding the areacella file, loading it, turning it into a cell measure and then adding it to the cube. This is a pain and involves about 100 lines of code. To make life easier, we wrap all of that away using `netcdf_scm`, which we will introduce in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading with `netcdf_scm`\n",
    "\n",
    "There are a couple of particularly annoying things involved with processing netCDF data. Firstly, the data is often stored in a folder hierarchy which can be fiddly to navigate. Secondly, the metadata is often stored separate from the variable cubes. \n",
    "\n",
    "Hence in `netcdf_scm`, we try to abstract the code which solves these two things away to make life a bit easier. This involves defining a cube in `netcdf_scm.iris_cube_wrappers`. The details can be read there, for now we just give an example.\n",
    "\n",
    "Our example uses `MarbleCMIP5Cube`. This cube is designed to work with the CMIP5 data on our server at University of Melbourne, which has been organised into a number of folders which are similar, but not quite identical, to the CMOR directory structure described in section 3.1 of the [CMIP5 Data Reference Syntax](https://cmip.llnl.gov/cmip5/docs/cmip5_data_reference_syntax_v1-00_clean.pdf). To facilitate our example, the test data in `DATA_PATH_TEST_MARBLE_CMIP5_ROOT` is organised in the same way.\n",
    "\n",
    "#### Loading with identifiers\n",
    "\n",
    "With our `MarbleCMIP5Cube`, we can simply pass in the information about the data we want (experiment, model, ensemble member etc.) and it will load our desired cube using the `load_data_from_identifiers` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas = MarbleCMIP5Cube()\n",
    "tas.load_data_from_identifiers(\n",
    "    root_dir=DATA_PATH_TEST_MARBLE_CMIP5_ROOT,\n",
    "    activity=\"cmip5\",\n",
    "    experiment=\"1pctCO2\",\n",
    "    modeling_realm=\"Amon\",\n",
    "    variable_name=\"tas\",\n",
    "    model=\"CanESM2\",\n",
    "    ensemble_member=\"r1i1p1\",\n",
    "    time_period=\"185001-198912\",\n",
    "    file_ext=\".nc\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify that the loaded cube is exactly the same as the cube we loaded in the previous section (where we provided the full path)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "assert tas.cube == tas_iris_load.cube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a look at our cube too (note that the broken cell measures representation is intended to be fixed in https://github.com/SciTools/iris/pull/3173)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas.cube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading with filepath\n",
    "\n",
    "With our `MarbleCMIP5Cube`, we can also pass in the filepath and the cube will determine the relevant attributes for us, as well as loading the other required cubes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_path = join(\n",
    "    DATA_PATH_TEST_MARBLE_CMIP5_ROOT,\n",
    "    \"cmip5\",\n",
    "    \"1pctCO2\",\n",
    "    \"Amon\",\n",
    "    \"tas\",\n",
    "    \"CanESM2\",\n",
    "    \"r1i1p1\",\n",
    "    \"tas_Amon_CanESM2_1pctCO2_r1i1p1_185001-198912.nc\",\n",
    ")\n",
    "example_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_from_path = MarbleCMIP5Cube()\n",
    "tas_from_path.load_data_from_path(example_path)\n",
    "tas_from_path.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also confirm that this cube is the same again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "assert tas_from_path.cube == tas_iris_load.cube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acting on the cube\n",
    "\n",
    "Once we have loaded our `SCMCube`, we can act on its `cube` attribute like any other Iris Cube. For example, we can add a year categorisation, take an annual mean and then plot the timeseries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.coord_categorisation.add_year(tas.cube, 'time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_mean = tas.cube.aggregated_by(\n",
    "    ['year'], # Do the averaging \n",
    "    iris.analysis.MEAN\n",
    ")\n",
    "global_annual_mean = annual_mean.collapsed(\n",
    "    ['latitude', 'longitude'], \n",
    "    iris.analysis.MEAN,\n",
    "    weights=iris.analysis.cartography.area_weights(annual_mean)\n",
    ")\n",
    "qplt.plot(global_annual_mean);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take a time average and make a spatial plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_mean = tas.cube.collapsed('time', iris.analysis.MEAN)\n",
    "qplt.contourf(\n",
    "    time_mean, \n",
    "    levels=np.arange(200, 320, 10), \n",
    "    extend='max',\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a spatial plot with coastlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "# we ignore output here as CI sometimes has to \n",
    "# download the map file\n",
    "qplt.contourf(\n",
    "    time_mean, \n",
    "    levels=np.arange(200, 320, 10), \n",
    "    extend='max',\n",
    ")\n",
    "plt.gca().coastlines();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCM specifics\n",
    "\n",
    "Finally, we present the key functions of this package. These are directly related to processing netCDF files for simple climate models.\n",
    "\n",
    "### Getting SCM timeseries\n",
    "\n",
    "The major one is `get_scm_timeseries`. This function wraps a number of steps:\n",
    "\n",
    "1. load the land surface fraction data\n",
    "1. combine the land surface fraction and latitude data to determine the hemisphere and land/ocean boxes\n",
    "1. cut the data into the relevant boxes\n",
    "1. take a time average in each box\n",
    "1. return it all as an OpenSCMDataframe\n",
    "\n",
    "As you can imagine, we find it very useful to be able to abstract all these normally nasty steps away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_scm_timeseries = tas.get_scm_timeseries()\n",
    "type(tas_scm_timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_scm_timeseries.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having the data as a Dataframe makes it trivial to plot and work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restricted_time_df = tas_scm_timeseries.filter(\n",
    "    year=range(1950, 1961),\n",
    "    region=\"*Ocean*\"  # Try e.g. \"*\", \"World\", \"*Land\", \"*Southern Hemisphere*\" here\n",
    ")\n",
    "restricted_time_df.line_plot(\n",
    "    x=\"time\", \n",
    "    color=\"region\", \n",
    "    figsize=(16, 9),\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_scm_timeseries_annual_mean = tas_scm_timeseries.filter(\n",
    "    region=\"World\"\n",
    ").timeseries().T\n",
    "tas_scm_timeseries_annual_mean = tas_scm_timeseries_annual_mean.groupby(\n",
    "    tas_scm_timeseries_annual_mean.index.map(lambda x: x.year)\n",
    ").mean()\n",
    "tas_scm_timeseries_annual_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_scm_timeseries_annual_mean.plot(figsize=(16, 9));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting SCM timeseries cubes\n",
    "\n",
    "As part of the process above, we calculate all the timeseries as `iris.cube.Cube`'s. Extracting these intermediate cubes can be done with `get_scm_timeseries_cubes`. These intermediate cubes are useful as they contain all the metadata from the source cube in a slightly more friendly format than `SCMDataFrame`'s `metadata` attribute [Note: `SCMDataFrame`'s metadata handling is a work in progress]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_scm_ts_cubes = tas.get_scm_timeseries_cubes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "tas_scm_ts_cubes[\"World\"].cube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular, the `land_fraction*` auxillary co-ordinates provide useful information about the fraction of area that was assumed to be land in the crunching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_scm_ts_cubes[\"World\"].cube.coords(\"land_fraction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_scm_ts_cubes[\"World\"].cube.coords(\"land_fraction_northern_hemisphere\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting SCM cubes\n",
    "\n",
    "Another utility function is `get_scm_cubes`. This function is very similar to `get_scm_timeseries` but returns cubes rather than a Dataframe. However, each of the cube's data is masked for the region of interest. Hence it is useful for spatial plots and other, more complicated than pure timeseries, analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_scm_cubes = tas.get_scm_cubes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 18))\n",
    "no_rows = 3\n",
    "no_cols = 4\n",
    "\n",
    "total_panels = no_cols * no_rows\n",
    "rows_plt_comp = no_rows*100\n",
    "cols_plt_comp = no_cols*10\n",
    "for i, (label, cube) in enumerate(tas_scm_cubes.items()):\n",
    "    if label == \"World\":\n",
    "        index = (int((no_rows + 1) / 2))\n",
    "        plt.subplot(no_rows, 1, index)\n",
    "    else:\n",
    "        if label == \"World|Northern Hemisphere\":\n",
    "            index = 1\n",
    "        elif label == \"World|Southern Hemisphere\":\n",
    "            index = 1 + (no_rows - 1) * no_cols\n",
    "        elif label == \"World|Land\":\n",
    "            index = 2\n",
    "        elif label == \"World|Ocean\":\n",
    "            index = 2 + (no_rows - 1) * no_cols\n",
    "        else:\n",
    "            index = 3\n",
    "            if \"Ocean\" in label:\n",
    "                index += 1\n",
    "            if \"Southern Hemisphere\" in label:\n",
    "                index += (no_rows - 1) * no_cols\n",
    "\n",
    "        plt.subplot(no_rows, no_cols, index)\n",
    "        \n",
    "    region_time_mean = cube.cube.collapsed('time', iris.analysis.MEAN)\n",
    "    qplt.contourf(\n",
    "        region_time_mean, \n",
    "        levels=np.arange(200, 320, 5), \n",
    "        extend='max',\n",
    "    )\n",
    "    plt.title(label)\n",
    "    plt.gca().coastlines()\n",
    "    \n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
